# lambda_corr — Repeated-Average-Rank Correlation Λ (Lambda)

`lambda_corr` introduces, and implements, the **Repeated-Average-Rank correlation Λ (Lambda)**, 
a new family of robust, symmetric and asymmetric measures of monotone association 
based on **pairwise rank slopes**. Compared with traditional rank-based measures 
(Spearman’s ρ and Kendall’s τ [1,2]), Lambda is:

- **Substantially more resistant to noise and outliers** (see /results/*Robustness*.png).
- **Much less biased relative to Pearson’s r [3] linear correlation** (see /results/\*bias\*.png).
- **Competitive or superior in accuracy** for moderate–strong signals (see /results/\*accuracy\*.png).
- Slightly less efficient asymptotically (~81% vs. ~91% for ρ and τ). 
  See /results/\*efficiency\*.png and /results/\*power\*.png (code for figures is in /tests/test_lambdacorr2.py)
  
The canonical statistic, **Λₛ**, combines a robust median-of-pairwise-slopes inner 
loop with an efficient outer mean (repeated-average, inspired by Seigel's repeated-median [4]), 
and uses a **signed geometric-mean symmetrization**, mirroring how:

- **Kendall’s τ_b** can be written as the signed geometric mean of **Somers’ D\_{Y|X}** and **D\_{X|Y}**;
- **Pearson’s r** is the signed geometric mean of the two OLS slopes
      $m_{Y\mid X} = \dfrac{\mathrm{cov}(X,Y)}{\mathrm{var}(X)}$ and $m_{X\mid Y} = \dfrac{\mathrm{cov}(X,Y)}{\mathrm{var}(Y)}$;
- **Spearman’s ρ** has the same construction applied to the **rank-transformed**
  variables \(r_X, r_Y\).
  
Λₛ extends this same geometric-mean construction to **robust repeated-average-rank correlations**
and ensures interpretability as a standard measure of monotonic trend/association.

---

## Canonical Definition of Λₛ

Given paired samples $(x_i, y_i)$, $i = 1,\dots,n$:

1. Compute **average ranks**:
```python
rx = rankdata(x, method="average")
ry = rankdata(y, method="average")
```

2. **Standardize** ranks to zero mean / unit variance:
```python
rxt = (rx - np.mean(rx)) / np.std(rx)
ryt = (ry - np.mean(ry)) / np.std(ry)
```

3. For each anchor point sample *i*, compute the **median slope in rank space**:

$$
b_i = \mathrm{median}_{j \ne i,\; rxt[j] \ne rxt[i]}
      \frac{\,ryt[j] - ryt[i]\,}{\,rxt[j] - rxt[i]\,}
$$

4. Compute the **asymmetric** rank-slope correlations as the outer mean over i slopes:
- **Λ(Y|X)**:

$$
\Lambda_{yx} = \frac{1}{n} \sum_i b_i
$$

- **Λ(X|Y)**: repeat with x and y swapped.

5. Define the **symmetric** Lambda:

$$
\Lambda_s = \mathrm{sgn}(\Lambda_{yx}) \sqrt{\left|\Lambda_{yx}\Lambda_{xy}\right|}
$$

If the asymmetric signs disagree (rare under the null), Λₛ = 0.

---

## Properties

- **Range:** Λₛ ∈ \([-1,1]\)
- **Robust: Very robust to outliers and noise**; extremely high sign-breakdown 
                  point (median-of-slopes core) with adversarial contamination
                  (see /results/\*Robustness\*.png).
- **Less biased:** Much less biased than Spearman or Kendall relative to Pearson 
                  (see /results/\*bias\*.png).
- **Accurate: Competitive or superior in accuracy** for moderate–strong signals.
- **Efficiency:** Asymptotic efficiency ~81% (ρ, τ ≈ 91%) with var_opt/var(Λₛ) = (1/N)/(1.112^2/N).
                  (Siegal median of medians is ~37%). 
                  See /results/\*efficiency\*.png and /results/\*power\*.png
- **Null distribution:** centered, symmetric, slightly heavier tails than Spearman.
- **Symmetric:** Λₛ(x,y) == Λₛ(y,x).
- **Invariant** under strictly monotone transforms.

---

## p-values

Lambda supports three p-value modes:

### `ptype="default"` (recommended)
- **n < 25** → Monte Carlo **permutation test**.
- **n ≥ 25** → **asymptotic Edgeworth approximation**.

### `ptype="perm"`
- Monte Carlo permutation p-values,
- Valid with **ties or arbitrary marginals**,
- Early stopping when p-uncertainty < `p_tol`,

### `ptype="asymp"`
- Fast asymptotic p-values.
- Best for low ties or larger n.
- Calibrated from very large unconditional Monte Carlo null distributions.

The permutation test samples from the *conditional* null distribution,
generated by permuting the observed y-values while keeping x fixed.
This distribution depends on the observed marginal distributions and tie structure.
    
In contrast, the asymptotic p-values approximate the *unconditional* null 
distribution of Λ, calibrated from extremely large independent Monte Carlo 
simulations. As a result, the asymptotic p-values may be more accurate and more 
stable than permutation p-values, especially for moderate n, skewed data, or 
substantial ties.

### Returned values
```
Lambda_s, p_s, Lambda_yx, p_yx, Lambda_xy, p_xy, Lambda_a
```
Where:

- **Λₛ** — symmetric correlation.
- **Λ(Y|X)** / **Λ(X|Y)** — asymmetric directional correlations.
- **p-values** correspond to the chosen `alt = {"two-sided","greater","less"}`.
- **Λₐ** — normalized asymmetry index with range [0, 1].

$$
\Lambda_a = \frac{\bigl|\Lambda_{yx} - \Lambda_{xy}\bigr|}
                 {\bigl|\Lambda_{yx}\bigr| + \bigl|\Lambda_{xy}\bigr|}
$$

with $\Lambda_a \in [0,1]$.

---
    
## Installation
The library targets Python 3.8+ and uses NumPy and Numba for speed.

```bash

#Install lambda-corr from pypi with pip
pip install lambda-corr

#Or local install from source
pip install -e .

#Prerequisites if necessary
pip install numba numpy

#Optional: statistical tests make use of SciPy
pip install scipy

#Optional: for Numba fast math optimizations on Intel CPUs
pip install icc_rt

```

Requirements:
- Python ≥ 3.8  
- NumPy ≥ 1.23
- Numba ≥ 0.61
- SciPy ≥ 1.9 (only needed for some validation tests)

## Quick Example
Compute the symmetric Lambda correlation Λ_s and its directional components
for a simple monotonic relationship:
```python

import numpy as np
import math
from lambda_corr import lambda_corr

rng = np.random.default_rng(seed=0)

n = 50
rho = 0.5   # correlation strength
x = rng.standard_normal(n)
z = rng.standard_normal(n)
c = math.sqrt((1 - rho) * (1 + rho))
y = np.exp(rho * x + c * z)   # any monotonic transformation

# Compute Lambda correlations
Lambda_s, p_s, Lambda_yx, p_yx, Lambda_xy, p_xy, Lambda_a = lambda_corr(x, y)

# Nicely formatted output
print(f"Λ_s       = {Lambda_s: .4f}   (p = {p_s: .4g})")
print(f"Λ(y|x)    = {Lambda_yx: .4f}   (p = {p_yx: .4g})")
print(f"Λ(x|y)    = {Lambda_xy: .4f}   (p = {p_xy: .4g})")
print(f"Asymmetry = {Lambda_a: .4f}")

# Example output:
# Λ_s       =  0.4130   (p =  0.0087)     #Result will be close to rho
# Λ(y|x)    =  0.4145   (p =  0.008419)
# Λ(x|y)    =  0.4114   (p =  0.008988)
# Asymmetry =  0.0038

```

## Notes
- A fully repeated-median Λ has maximal robustness but reduced asymptotic 
  efficiency, while a mean-of-medians variant recovers much of the efficiency 
  at minimal loss of breakdown.
- A mean-of-means Λ is Theil-Sen in rank-space and is essentially Spearman in 
  both efficiency and null spread but gives up most of the robustness advantage 
  compared to mean of medians.
- Continuum of Lambda variants behavior (outside loop - inside loop):
  Spearman (ρ) ≈ Λₛ^(mean-mean)  <->  Λₛ^(mean-median)  <-> Λₛ^(median-mean)  <->  
                                                          Λₛ^(median-median) ≈ Siegel
  Canonical choice: Λₛ^(mean-median) — best efficiency/robustness balance 
                                              especially at low statistics)

## Implementation Notes
- Skip vertical pairs where rxt[j] == rxt[i].
- If all slopes for an i are undefined (e.g., all rxt equal), its contribution is 
  NaN and is ignored.
- If asymmetric Λ_xy/Λ_yx have opposite signs Λₛ is taken as zero.
    
## References
[1] Spearman, C. The proof and measurement of association between two things. 
      American Journal of Psychology, 15(1), 72–101, 1904.
      
[2] Kendall, M.G., Rank Correlation Methods (4th Edition), Charles 
      Griffin & Co., 1970.
      
[3] https://en.wikipedia.org/wiki/Pearson_correlation_coefficient

[4]Siegel, A.F., Robust Regression Using Repeated Medians, Biometrika, 
      Vol. 69, pp. 242-244, 1982.
      
## Dependencies
- Python ≥ 3.8  
- NumPy ≥ 1.23
- Numba ≥ 0.61
- SciPy ≥ 1.9 #If needed for verification of statistical testing

## Citation
If you use lambda_corr in academic or scientific work, please cite:
```bash
Lundquist, J.P.  lambda_corr: Robust Repeated-Average-Rank Correlation Λ (Lambda).
GitHub repository: https://github.com/JonPaulLundquist/lambda_corr
```

```bash
@misc{lundquist2025lambda_corr,
  author       = {Lundquist, Jon Paul},
  title        = {lambda\_corr: Robust Repeated-Average-Rank Correlation (Λ)},
  year         = {2025},
  publisher    = {GitHub},
  howpublished = {\url{https://github.com/JonPaulLundquist/lambda_corr}},
  note         = {Version X.Y.Z. Accessed: YYYY-MM-DD}
}
```
## License
This project is licensed under the MIT license.  
See the full text in [LICENSE](./LICENSE).
